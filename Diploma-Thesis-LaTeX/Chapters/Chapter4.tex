
\chapter{Ο αλγόριθμος \textlatin{Locally Linear Embeddings - LLE}}
\numberwithin{equation}{section}
\par
Ο αλγόριθμος \textlatin{LLE} ανήκει στην κατηγορία αλγορίθμων μη γραμμικής μείωσης διαστάσεων με την χρήση γράφων και αποτελεί μια απο τις αποτελεσματικότερες αλλά και γρηγορότερες τεχνικές αυτού του είδους. Όπως αναφέραμε και στο προηγούμενο κεφάλαιο, βασική υπόθεση της μεθόδου είναι ότι τα δεδομένα μας βρίσκονται σε μια αρκετά λεία πολλαπλότητα, διάστασης $m$, και η οποία είναι ενσωματωμένη στον υποχώρο του $ \Re^{N} $, με $m<N$. Η υπόθεση για το λείο της πολλαπλότητας μας επιτρέπει να υποθέσουμε επιπλέον ότι, με δεδομένη την ύπαρξη αρκετών δεδομένων και ότι η πολλαπλότητα είναι $\ll$καλά$\gg$ δειγματοληπτημένη, τα κοντινά σημεία βρίσκονται πάνω (ή κοντά) σε ένα $\ll$τοπικό$\gg$ γραμμικό τμήμα της πολλαπλότητας.

\section{Ο αλγόριθμος ως τεχνική μη γραμμικής μείωσης διαστάσεων}
\par
Δεδομένης της αποτελεσματικότητας του αλγορίθμου να ανακαλύπτει τον χώρο μειωμένης διάστασης στον οποίο βρίσκεται ενσωματωμένη η πληροφορία ενός προβλήματος, ο αλγόριθμος έχει χρησιμοποιηθεί με επιτυχία σε αρκετές πρακτικές εφαρμογές. Ιδιαίτερο ενδιαφέρον παρουσιάζουν νέες μελέτες κυρίως απο τον χώρο της Ιατρικής \cite{1} \cite{2}. Απο τις αναφορές αυτές είναι φανερό ότι ο ρόλος της μείωσης των διαστάσεων μπορεί να καθορίσει σε μεγάλο βαθμό την βελτίωση του αποτελέσματος ταξινόμησης. Στις συγκεκριμένες περιπτώσεις στόχος είναι να γίνει σωστή πρόβλεψη για το αν κάποιος ασθενής πάσχει απο μια συγκεκριμένη ασθένεια ή βρίσκεται στην ευπαθή ομάδα με μεγάλη πιθανότητα να του παρουσιαστεί στο μέλλον. Φαίνεται οτι ο αλγόριθμος \textlatin{LLE} είναι ένα πολύ ισχυρό εργαλείο το οποίο μπορεί να υλοποιήσει την μείωση των διαστάσεων σε τέτοιου είδους εφαρμογές και μάλιστα επιφέροντας σημαντικά και ουσιαστικά αποτελέσματα. Ο αλγόριθμος επίσης, έχει χρησιμοποιηθεί και σε εφαρμογές ταξινόμησης με σετ δεδομένων ευρέως διαδεδομένα στον χώρο της αναγνώρισης προτύπων \cite{3} \cite{4} \cite{5}, όπως το σετ δεδομένων με χειρόγραφα ψηφία \textlatin{MNIST}.

\section{Μαθηματική ανάλυση και υλοποίηση του αλγορίθμου \textlatin{Locally Linear Embeddings} σε κώδικα \textlatin{MATLAB}}
\par
Ο αλγόριθμος \textlatin{LLE}\cite{lle} αποτελεί το κύριο κομμάτι της εν λόγω διατριβής και η υλοποίηση του έχει στηριχθεί στον αλγόριθμο της παραπάνω αναφοράς. Ο ψευδοκώδικας είναι διαθέσιμος στην παρακάτω τοποθεσία \href{https://www.cs.nyu.edu/~roweis/lle/algorithm.html}{\textlatin{LLE Algorithm Pseudocode}}. Παρ' όλα αυτά στην συγκεκριμένη υλοποίηση έχουν γίνει συγκεκριμένες βελτιστοποιήσεις σε κάποια βήματα του αλγορίθμου, όπως για παράδειγμα η χρήση του \href{http://autogpu.ee.auth.gr/doku.php?id=cuknns:gpu_accelerated_k-nearest_neighbor_library}{αλγορίθμου κοντινότερων γειτόνων}, υλοποιημένο σε \textlatin{CUDA}, με σκοπό την μείωση του χρόνου εκτέλεσης του συγκεκριμένου βήματος. 

\subsection{Βήμα-1: Εύρεση του πίνακα γειτνίασης}
\par
Κατά το πρώτο βήμα του αλγορίθμου γίνεται ο υπολογισμός των κοντινότερων γειτόνων για κάθε σημείο $X_{i}$ του συνόλου των δεδομένων. Στο βήμα αυτό ο χρήστης επιλέγει ανάλογα με την κάθε εφαρμογή έναν αριθμό γειτόνων \textlatin{K} και χρησιμοποιεί κάποιον αλγόριθμο υπολογισμού κοντινότερων γειτόνων για κάθε ένα απο τα σημεία του δείγματος. Με τον τρόπο αυτό έχει υπολογιστεί ο τετραγωνικός πίνακας $N \times N$, ο οποίος δίνει πληροφορία για κάθε σημείο του δείγματος ως προς τους \textlatin{K} κοντινότερους γείτονές του.
\par
Ο τρόπος υπολογισμού του πίνακα αυτού στην συγκεκριμένη υλοποίηση γίνεται μέσω της συνάρτησης \textlatin{knnsearch} του \textlatin{MATLAB} για την σειριακή υλοποίηση και με την συνάρτηση \textlatin{gpu\textunderscore knn} για την παράλληλη υλοποίηση. Η συνάρτηση αυτή αντιπροσωπεύει την κύρια συνάρτηση \textlatin{gpuknnHeap} του πακέτου \href{http://autogpu.ee.auth.gr/doku.php?id=cuknns:gpu_accelerated_k-nearest_neighbor_library}{\textlatin{knn-toolbox}}, η οποία με την σειρά της αποτελεί το πέρασμα απο τον κώδικα \textlatin{MATLAB} στην συνάρτηση πυρήνα υπολογισμού κοντινότερων γειτόνων με τη χρήση παράλληλης υλοποίησης σε \textlatin{CUDA} γραμμένη στην γλώσσα προγραμματισμού \textlatin{C}. Η υλοποίηση αυτή χρησιμοποιεί την Ευκλείδια απόσταση ως μέθοδο προσδιορισμού των κοντινότερων γειτόνων. Παρ' όλα αυτά στο βήμα αυτό μπορούν να χρησιμοποιηθούν και άλλες μετρικές γειτνίασης όπως για παράδειγμα ο προσδιορισμός κοντινών γειτόνων με τη χρήση σφαίρας ακτίνας $\epsilon$. Επίσης, μια άλλη γνωστή μέθοδος επίλυσης του βήματος αυτού η οποία βελτιώνει τον χρόνο εκτέλεσης είναι η χρήση \href{https://en.wikipedia.org/wiki/K-d_tree}{\textlatin{KD-trees}}.

\subsection{Βήμα-2: Εύρεση του πίνακα βαρών \textlatin{W}}
\par
Στο δεύτερο αυτό βήμα του αλγορίθμου στόχος είναι να υπολογιστεί ο πίνακας βαρών $W(i,j),i,j=1,2,\ldots,n,$ μέσω των οποίων είναι εφικτή η ανακατασκευή του κάθε δείγματος $X_{i}$ μέσω των βαρών που αντιστοιχούν στους κοντινούτερους γείτονές του. Πιο απλά στο βήμα αυτό θέλουμε να προσδιορίζουμε κάθε σημείο $X_{i}$ του δείγματός μας, ελαχιστοποιώντας την συνάρτηση κόστους
\newline\hspace*{\fill}
\begin{equation}
        \arg \min_{w} E_{w} = \sum_{i=1}^{n} \Vert \mathbf{X_{i}} - \sum_{j=1}^{n} W(i,j)\mathbf{X}_{j} \Vert ^{2}
\end{equation}
\hspace*{\fill}\newline
η οποία στην πραγματικότητα αυτό που προσπαθεί να ανακαλύψει είναι οι κοντινότεροι γείτονες $j$ του σημείου $X_{i}$ οι οποίοι ασκούν την σημαντικότερη επιρροή πάνω του ως προς την ανακατασκευή του. Η ελαχιστοποίηση της συνάρτησης αυτής γίνεται εφαρμόζοντας τον αλγόριθμο ελαχίστων τετραγώνω \href{https://en.wikipedia.org/wiki/Least_squares}{\textlatin{Least squares}} εξασφαλίζοντας παράλληλα κάποιες απαραίτητες ιδιότητες για τον πίνακα βαρών $W$. Καταρχήν θα πρέπει να ισχύει ότι το κάθε δείγμα $X_{i}$ θα πρέπει να μπορεί αν ανακατασκευαστεί μόνο απο τους κοντινότερους γείτονές του γεγονός που θέτει τον περιορισμό $W(i,j)=0$ στην περίπτωση κατά την οποία το $j$ στοιχείο δεν είναι γείτονας του $i$. Επίσης θα πρέπει τα στοιχεία κάθε γραμμής του μητρώου βαρών $W$ να αθροίζονται στην μονάδα, δηλαδή $\sum_{j=1}^{n} W(i,j)=1$, ώστε να εξασφαλιστεί η αμεταβλητότητα κατά την μεταφορά. Με τους περιορισμούς αυτούς λοιπόν εξασφαλίζεται ότι τα βάρη τα οποία ελαχιστοποιούν την παραπάνω συνάρτηση κόστους είναι αμετάβλητα κατά την περιστροφή, την μεταφορά και την κλιμάκωση.
\par
Η παραπάνω διαδικασία υλοποιείται με τον παρακάτω κώδικα σε 
\textlatin{MATLAB}.

\selectlanguage{english}
\begin{lstlisting}[language=Matlab]
W = zeros(K,N);
for ii=1:N
   z = X(:,neighborhood(:,ii))-repmat(X(:,ii),1,K); 
   C = z'*z;                                        % local covariance
   C = C + eye(K,K)*tol*trace(C);                   % regularlization (K>D)
   W(:,ii) = C\ones(K,1);                           % solve Cw=1
   W(:,ii) = W(:,ii)/sum(W(:,ii));                  % enforce sum(w)=1
end;
\end{lstlisting}
\selectlanguage{greek}
Για να γίνει κατανοητή η παραπάνω διαδικασία ακολουθούμε τον εξής συλλογισμό. Ας πάρουμε για παράδειγμα ένα σημείο $x$ το οποίο έχει $K$ κοντινούς γείτονες $n_{j}$ και βάρη ανακατασκευής $w_{j}$ για τα οποία ισχύει η συνθήκη $\sum_{j} w_{j} = 1$. Τότε μπορούμε να γράψουμε την συνάρτηση κόστους ως
\newline\hspace*{\fill}
\begin{equation}
        \epsilon = \mid \overrightarrow{x} - \sum_{j} w_{j}\overrightarrow{n}_{j} \mid ^{2} = \mid \sum_{j} w_{j}(\overrightarrow{x}-\overrightarrow{n}_{j}) \mid ^{2} = \sum_{jk} w_{j}w_{k}C_{jk}
\end{equation}
\hspace*{\fill}\newline
Στην παραπάνω σχέση χρησιμοποιήσαμε το μητρώο \textlatin{Gram} το οποίο ορίζεται ως
\newline\hspace*{\fill}
\begin{equation}
        C_{jk} = (\overrightarrow{x}-\overrightarrow{n}_{j})
        \cdot(\overrightarrow{x}-\overrightarrow{n}_{k})
\end{equation}
\hspace*{\fill}\newline
Εκ κατασκευής για τον πίνακα \textlatin{Gram} έχουμε ότι είναι συμμετρικός και θετικά ημιορισμένος. Σύμφωνα με τα παραπάνω λοιπόν τα βέλτιστα βάρη ανακατασκευής $w_{j}$ της συνάρτησης κόστους μπορούν να υπολογιστούν, αφού μέσω του πολλαπλασιαστή \textlatin{Lagrange} εξασφαλίσουμε τη συνθήκη $\sum_{j} w_{j} = 1$, μέσω της επίλυσης του συστήματος
\newline\hspace*{\fill}
\begin{equation}
	w_{j} = \dfrac{\sum_{k}C_{jk}^{-1}}{\sum_{lm}G_{lm}^{-1}}
\end{equation}
\hspace*{\fill}\newline
Όπως είχαμε αναφέρει στην παράγραφο (2.3) οι πίνακες $X_{T}X$(πίνακας συνδιασποράς) και $XX_{T}$(πίνακας \textlatin{Gram}) έχουν τις ίδιες ιδιοτιμές και ιδιοδιανύσματα τα οποία σχετίζονται μεταξύ τους. Για τον λόγο αυτό μπορεί να παραληφθεί η αντιστροφή του πίνακα \textlatin{Gram}, όπως φαίνεται και στην υλοποίηση που παρατέθηκε παραπάνω, λύνοντας το σύστημα $\sum_{j}C_{jk}w_{k}=1$ και έπειτα απαιτώντας τον περιορισμό $\sum_{j} w_{j}=1$ ο οποίος υλοποιείται με την τελευταία γραμμή του παραπάνω κώδικα. Επίσης βλέπουμε ότι στην υλοποίηση του κώδικα δεν υπολογίζεται ο πίνακας \textlatin{Gram} αλλά αυτός της συνδιασποράς και στην συνέχεια ακολουθείται η διαδικασία που αναλύθηκε παραπάνω. Τελευταία διευκρίνηση για την παραπάνω διαδικασία, η γραμμή 5 του κώδικα, στην οποία γίνεται κανονικοποίηση του πίνακα συνδιασποράς. Αυτό απαιτείται στην περίπτωση για την οποία ο πίνακας συνδιασποράς προκύπτει μοναδιαίος ή πολύ κοντά σε αυτόν, οπότε και δεν υπάρχει μοναδική λύση του συστήματος.
\par
Καταλήγουμε λοιπόν μέσω της παραπάνω διαδικασίας στον υπολογισμό του μητρώου βαρών \textlatin{W} για το σύνολο των δεδομένων. Ο τρόπος μάλιστα με τον οποίο έγινε ο υπολογισμός αυτός εξασφαλίζει το γεγονός ότι η εσωτερική ενσωματωμένη γεωμετρία η οποία υπάρχει στην γειτονιά ενός σημείο $X_{i}$ του συνόλου των δεδομένων θα εξακολουθεί να υπάρχει και στον χώρο της μειωμένης διάστασης. Το γεγονός αυτό εξασφαλίζεται απο την ανεξαρτησία των βαρών ως προς την περιστροφή, την μεταφορά και την κλιμάκωση αλλά και απο το γεγονός ότι οι γείτονες του σημείου $X_{i}$ στον χώρο αρχικών διαστάσεων $D$ θα εξακολουθούν να αποτελούν γείτονες του σημείου $Y_{i}$ (προβολή του $X_{i}$ απο τον χώρο υψηλής διάστασης στο σημέιο $Y_{i}$ χαμηλής διάστασης). Αυτό συμβαίνει επίσης, διότι όπως θα δούμε παρακάτω με τα βάρη με τα οποία γίνεται ανακατασκεύη του $X_{i}$ τα ίδια θα χρησιμοποιηθούν και για την κατασκευή του $Y_{i}$ στον χώρο μειωμένης διάστασης. Συνέπεια λοιπόν των παραπάνω είναι ότι τα βάρη $w_{j}$ που υπολογίστηκαν δεν εξαρτώνται απο το εκάστοτε σημείο αλλά κωδικοποιούν πληροφορία σχετική με τα εγγενή χαρακτηριστικά κάθε γειτονιάς τα οποία και διατηρούνται κατά την ενσωμάτωση των δεδομένων στον χώρο χαμηλότερης διάστασης. 

\subsection{Βήμα-4: Επιλογή των τελικών διαστάσεων με τη χρήση του πίνακα \textlatin{W}}
\par
Στο τελευταίο βήμα του αλγορίθμου πραγματοποιείται η μείωση των διαστάσεων των δειγμάτων απο τον χώρο υψηλής διάστασης $D$ σε έναν χαμηλότερης $d$. Η διαδικασία αυτή πραγματοποιείται όπως αναφέραμε και παραπάνω χρησιμοποιώντας τον πίνακα των βαρών $W$ και τα οποία έχουν την ιδιότητα ότι αντανακλούν τις εγγενείς ιδιότητες της τοπικής γεωμετρίας στην οποία υπόκεινται τα δεδομένα. Η λύση λοιπόν προκύπτει επιλύοντας και πάλι ένα πρόβλημα ελαχιστοποίησης το οποίο ορίζεται ως
\newline\hspace*{\fill}
\begin{equation}
        \arg \min_{w} E_{y} = \sum_{i=1}^{n} \Vert \mathbf{Y_{i}} - \sum_{j=1}^{n} W(i,j)\mathbf{Y}_{j} \Vert ^{2}
\end{equation}
\hspace*{\fill}\newline
Και σε αυτή την περίπτωση  απαιτούμε την διατήρηση των συνθηκών, $\sum_{i} Y_{i} = 0$ ώστε να εξασφαλιστεί η αμεταβλητότητα ως προς την μεταφορά, και $ \dfrac{1}{N} \sum_{i} Y_{i}Y{i}^{T} = I $ η οποία εξασφαλίζει ότι οι διαστάσεις $d$ θα είναι δευτέρου βαθμού ασυσχέτιστες , ότι τα βάρη ανακατασκευής για τις διαστάσεις $d$ θα υπολογιστούν σε κοινή κλίμακα και ότι αυτή η κλίμακα θα είναι μοναδιαίου βαθμού.
\par



